{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Jonathan Bunch\n",
    "\n",
    "6 November 2021\n",
    "\n",
    "Bellevue University\n",
    "\n",
    "DSC550-T301\n",
    "\n",
    "---\n",
    "\n",
    "# Final Project Milestone Four\n",
    "\n",
    "This week I wanted to focus on feature selection, as this was a weakness in my analysis last week.  I had essentially\n",
    "chosen a random number of features based on those feature's correlation with the target feature.  This week I employed\n",
    "the \"SelectKBest\" and \"chi2\" methods from sklearn to quantitatively determine the best features for my regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Import my finished data set from the previous milestone.\n",
    "df8 = pd.read_csv('week-8-data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Model Results for  24  Best Features:\n",
      "R-squared score:             0.7762115773224278\n",
      "Explained Variance Score:    0.7777247233392993\n",
      "Mean Absolute Error:         287079309.9112983\n",
      "Mean Squared Error:          1.6995626644758458e+17\n",
      "\n",
      "Regression Model Results for  23  Best Features:\n",
      "R-squared score:             0.7785333832297617\n",
      "Explained Variance Score:    0.7794399941720883\n",
      "Mean Absolute Error:         268014779.46989715\n",
      "Mean Squared Error:          1.6819296940699123e+17\n",
      "\n",
      "Regression Model Results for  22  Best Features:\n",
      "R-squared score:             0.7786227476521608\n",
      "Explained Variance Score:    0.783922581549676\n",
      "Mean Absolute Error:         276602681.96570164\n",
      "Mean Squared Error:          1.681251015369627e+17\n",
      "\n",
      "Regression Model Results for  21  Best Features:\n",
      "R-squared score:             0.7751079941605327\n",
      "Explained Variance Score:    0.778147493290234\n",
      "Mean Absolute Error:         272610231.92357\n",
      "Mean Squared Error:          1.7079438341389594e+17\n",
      "\n",
      "Regression Model Results for  20  Best Features:\n",
      "R-squared score:             0.7791278494540841\n",
      "Explained Variance Score:    0.7840674829120422\n",
      "Mean Absolute Error:         294420420.9812535\n",
      "Mean Squared Error:          1.677415016375411e+17\n",
      "\n",
      "Regression Model Results for  19  Best Features:\n",
      "R-squared score:             0.8046644001711996\n",
      "Explained Variance Score:    0.8047170953685409\n",
      "Mean Absolute Error:         284826513.62975913\n",
      "Mean Squared Error:          1.483477512106773e+17\n",
      "\n",
      "Regression Model Results for  18  Best Features:\n",
      "R-squared score:             0.5799709009318215\n",
      "Explained Variance Score:    0.6075792386201115\n",
      "Mean Absolute Error:         418443416.8952559\n",
      "Mean Squared Error:          3.1899137865510566e+17\n",
      "\n",
      "Regression Model Results for  17  Best Features:\n",
      "R-squared score:             0.5769229169089504\n",
      "Explained Variance Score:    0.6058385482919247\n",
      "Mean Absolute Error:         413917647.88137925\n",
      "Mean Squared Error:          3.213061721485359e+17\n",
      "\n",
      "Regression Model Results for  16  Best Features:\n",
      "R-squared score:             0.5879990523823373\n",
      "Explained Variance Score:    0.6270098126361903\n",
      "Mean Absolute Error:         397424081.1741032\n",
      "Mean Squared Error:          3.128943936963651e+17\n",
      "\n",
      "Regression Model Results for  15  Best Features:\n",
      "R-squared score:             0.5723454947075708\n",
      "Explained Variance Score:    0.59266929383501\n",
      "Mean Absolute Error:         427809273.4077936\n",
      "Mean Squared Error:          3.2478249848388704e+17\n",
      "\n",
      "Regression Model Results for  14  Best Features:\n",
      "R-squared score:             0.6286301728482893\n",
      "Explained Variance Score:    0.6455990540559697\n",
      "Mean Absolute Error:         387946252.73803973\n",
      "Mean Squared Error:          2.8203706223411827e+17\n",
      "\n",
      "Regression Model Results for  13  Best Features:\n",
      "R-squared score:             0.7462153156804459\n",
      "Explained Variance Score:    0.7728093020986583\n",
      "Mean Absolute Error:         284093003.66457367\n",
      "Mean Squared Error:          1.9273694730256013e+17\n",
      "\n",
      "Regression Model Results for  12  Best Features:\n",
      "R-squared score:             0.744895997938096\n",
      "Explained Variance Score:    0.7705183623343581\n",
      "Mean Absolute Error:         285158761.3553794\n",
      "Mean Squared Error:          1.9373890403948608e+17\n",
      "\n",
      "Regression Model Results for  11  Best Features:\n",
      "R-squared score:             0.7658147569080269\n",
      "Explained Variance Score:    0.7941958125789117\n",
      "Mean Absolute Error:         258665070.57451487\n",
      "Mean Squared Error:          1.7785213862638566e+17\n",
      "\n",
      "Regression Model Results for  10  Best Features:\n",
      "R-squared score:             0.7603863341935118\n",
      "Explained Variance Score:    0.8016159461530008\n",
      "Mean Absolute Error:         266529367.02233374\n",
      "Mean Squared Error:          1.8197475786745117e+17\n",
      "\n",
      "Regression Model Results for  9  Best Features:\n",
      "R-squared score:             0.7038821621853836\n",
      "Explained Variance Score:    0.7653518666629779\n",
      "Mean Absolute Error:         304901274.9815509\n",
      "Mean Squared Error:          2.2488688888081302e+17\n",
      "\n",
      "Regression Model Results for  8  Best Features:\n",
      "R-squared score:             0.7050830921256775\n",
      "Explained Variance Score:    0.7655542160996979\n",
      "Mean Absolute Error:         301259857.9505156\n",
      "Mean Squared Error:          2.2397484183889987e+17\n",
      "\n",
      "Regression Model Results for  7  Best Features:\n",
      "R-squared score:             0.7263804583194187\n",
      "Explained Variance Score:    0.7778610521276448\n",
      "Mean Absolute Error:         288867925.384437\n",
      "Mean Squared Error:          2.078005429178592e+17\n",
      "\n",
      "Regression Model Results for  6  Best Features:\n",
      "R-squared score:             0.7820687426993217\n",
      "Explained Variance Score:    0.8352684537176487\n",
      "Mean Absolute Error:         282287310.4297555\n",
      "Mean Squared Error:          1.6550803830641226e+17\n",
      "\n",
      "Regression Model Results for  5  Best Features:\n",
      "R-squared score:             0.7827199593702088\n",
      "Explained Variance Score:    0.8417171884466026\n",
      "Mean Absolute Error:         278282460.236372\n",
      "Mean Squared Error:          1.6501347137257293e+17\n",
      "\n",
      "Regression Model Results for  4  Best Features:\n",
      "R-squared score:             0.7623877757388033\n",
      "Explained Variance Score:    0.8121950319706132\n",
      "Mean Absolute Error:         278361021.2525883\n",
      "Mean Squared Error:          1.8045476175469008e+17\n",
      "\n",
      "Regression Model Results for  3  Best Features:\n",
      "R-squared score:             0.693598324863993\n",
      "Explained Variance Score:    0.7637387420840651\n",
      "Mean Absolute Error:         308099608.3322006\n",
      "Mean Squared Error:          2.3269695597448054e+17\n",
      "\n",
      "Regression Model Results for  2  Best Features:\n",
      "R-squared score:             0.7442353406438478\n",
      "Explained Variance Score:    0.7861395934630191\n",
      "Mean Absolute Error:         267700953.34099546\n",
      "Mean Squared Error:          1.9424064066101626e+17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign the predictive and target features to variables for convenience.\n",
    "y = df8.inflation_adjusted_gross\n",
    "X = df8.drop(columns=\"inflation_adjusted_gross\")\n",
    "\n",
    "# Create a list of descending k values to try for the SelectKBest method.\n",
    "k_vals = [b for b in range(2, 25)]\n",
    "k_vals.reverse()\n",
    "\n",
    "# Create and test models for number of best features.\n",
    "for k in k_vals:\n",
    "    X_k = SelectKBest(chi2, k=k).fit_transform(X, y)\n",
    "    # Split the data into training and testing sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_k, y, test_size=0.2, random_state=4)\n",
    "    # Create and fit a linear regression model.\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    # Use the model to make some predictions.\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    evs = explained_variance_score(y_test, y_pred)\n",
    "    # Print the results.\n",
    "    print('Regression Model Results for ', k, ' Best Features:')\n",
    "    print(\"R-squared score:            \", r2)\n",
    "    print(\"Explained Variance Score:   \", evs)\n",
    "    print(\"Mean Absolute Error:        \", mae)\n",
    "    print(\"Mean Squared Error:         \", mse)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like the best performing models are those that include the 19, 6, and 5 best features, according to the chi2\n",
    "test.  Next, I will see which features are included in each of these top performing models, and create a new dataframe\n",
    "for each selection of features."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 5 Features:\n",
      "['genre_Adventure' 'genre_Comedy' 'genre_Drama' 'mortality'\n",
      " 'income_per_cap']\n",
      "5 Feature Model Results:\n",
      "R-squared score:             0.7827199593702088\n",
      "Explained Variance Score:    0.8417171884466026\n",
      "Mean Absolute Error:         278282460.236372\n",
      "Mean Squared Error:          1.6501347137257293e+17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the selector for the 5 best features.\n",
    "selector_5 = SelectKBest(chi2, k=5)\n",
    "selector_5.fit(X, y)\n",
    "# Create a new dataframe with the k best columns.\n",
    "cols = selector_5.get_support(indices=True)\n",
    "X_best_5 = X.iloc[:, cols]\n",
    "\n",
    "# Check the results of the model again using this selection of features.\n",
    "X_5 = selector_5.fit_transform(X_best_5, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_5, y, test_size=0.2, random_state=4)\n",
    "# Create and fit a linear regression model.\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Use the model to make some predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "print('Best 5 Features:')\n",
    "print(X_best_5.columns.values)\n",
    "print('5 Feature Model Results:')\n",
    "print(\"R-squared score:            \", r2)\n",
    "print(\"Explained Variance Score:   \", evs)\n",
    "print(\"Mean Absolute Error:        \", mae)\n",
    "print(\"Mean Squared Error:         \", mse)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 6 Features:\n",
      "['month_1' 'genre_Adventure' 'genre_Comedy' 'genre_Drama' 'mortality'\n",
      " 'income_per_cap']\n",
      "6 Feature Model Results:\n",
      "R-squared score:             0.7820687426993217\n",
      "Explained Variance Score:    0.8352684537176487\n",
      "Mean Absolute Error:         282287310.4297555\n",
      "Mean Squared Error:          1.6550803830641226e+17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the selector for the 6 best features.\n",
    "selector_6 = SelectKBest(chi2, k=6)\n",
    "selector_6.fit(X, y)\n",
    "# Create a new dataframe with the k best columns.\n",
    "cols = selector_6.get_support(indices=True)\n",
    "X_best_6 = X.iloc[:, cols]\n",
    "\n",
    "# Check the results of the model again using this selection of features.\n",
    "X_6 = selector_6.fit_transform(X_best_6, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_6, y, test_size=0.2, random_state=4)\n",
    "# Create and fit a linear regression model.\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Use the model to make some predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "print('Best 6 Features:')\n",
    "print(X_best_6.columns.values)\n",
    "print('6 Feature Model Results:')\n",
    "print(\"R-squared score:            \", r2)\n",
    "print(\"Explained Variance Score:   \", evs)\n",
    "print(\"Mean Absolute Error:        \", mae)\n",
    "print(\"Mean Squared Error:         \", mse)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 19 Features:\n",
      "['month_1' 'month_2' 'month_3' 'month_4' 'month_5' 'month_9' 'month_10'\n",
      " 'month_12' 'genre_Adventure' 'genre_Black Comedy' 'genre_Comedy'\n",
      " 'genre_Concert/Performance' 'genre_Documentary' 'genre_Drama'\n",
      " 'genre_Musical' 'genre_Romantic Comedy' 'genre_Western' 'mortality'\n",
      " 'income_per_cap']\n",
      "19 Feature Model Results:\n",
      "R-squared score:             0.8046644001711996\n",
      "Explained Variance Score:    0.8047170953685409\n",
      "Mean Absolute Error:         284826513.62975913\n",
      "Mean Squared Error:          1.483477512106773e+17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the selector for the 19 best features.\n",
    "selector_19 = SelectKBest(chi2, k=19)\n",
    "selector_19.fit(X, y)\n",
    "# Create a new dataframe with the k best columns.\n",
    "cols = selector_19.get_support(indices=True)\n",
    "X_best_19 = X.iloc[:, cols]\n",
    "\n",
    "# Check the results of the model again using this selection of features.\n",
    "X_19 = selector_19.fit_transform(X_best_19, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_19, y, test_size=0.2, random_state=4)\n",
    "# Create and fit a linear regression model.\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Use the model to make some predictions.\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "print('Best 19 Features:')\n",
    "print(X_best_19.columns.values)\n",
    "print('19 Feature Model Results:')\n",
    "print(\"R-squared score:            \", r2)\n",
    "print(\"Explained Variance Score:   \", evs)\n",
    "print(\"Mean Absolute Error:        \", mae)\n",
    "print(\"Mean Squared Error:         \", mse)\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the final project submission, I will continue to refine the feature selection as I also expand on model selection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2f3a5d6e",
   "language": "python",
   "display_name": "PyCharm (dsc550)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}